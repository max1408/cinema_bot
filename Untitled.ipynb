{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov import configs, build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 11:23:47.167 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 100: [loading vocabulary from /home/popov/.deeppavlov/models/ner_ontonotes/tag.dict]\n",
      "2018-11-29 11:23:47.177 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 100: [loading vocabulary from /home/popov/.deeppavlov/models/ner_ontonotes/char.dict]\n",
      "Using TensorFlow backend.\n",
      "2018-11-29 11:23:52.394 WARNING in 'gensim.models.doc2vec'['doc2vec'] at line 75: Slow version of gensim.models.doc2vec is being used\n",
      "2018-11-29 11:23:52.415 INFO in 'summa.preprocessing.cleaner'['textcleaner'] at line 20: 'pattern' package not found; tag filters are not available for English\n",
      "2018-11-29 11:23:52.455 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/home/popov/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
      "2018-11-29 11:23:52.456 INFO in 'gensim.models.keyedvectors'['keyedvectors'] at line 204: loading projection weights from /home/popov/.deeppavlov/downloads/embeddings/glove.6B.100d.txt\n",
      "2018-11-29 11:23:52.457 DEBUG in 'smart_open.smart_open_lib'['smart_open_lib'] at line 176: {'kw': {}, 'mode': 'rb', 'uri': '/home/popov/.deeppavlov/downloads/embeddings/glove.6B.100d.txt'}\n",
      "2018-11-29 11:24:39.183 INFO in 'gensim.models.keyedvectors'['keyedvectors'] at line 266: loaded (400000, 100) matrix from /home/popov/.deeppavlov/downloads/embeddings/glove.6B.100d.txt\n",
      "2018-11-29 11:24:49.522 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 757: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2018-11-29 11:24:49.759 WARNING in 'tensorflow'['tf_logging'] at line 125: From /home/popov/Documents/bots/env/lib/python3.6/site-packages/deeppavlov/core/layers/tf_layers.py:862: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n",
      "2018-11-29 11:24:49.780 WARNING in 'tensorflow'['tf_logging'] at line 125: From /home/popov/Documents/bots/env/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n",
      "2018-11-29 11:24:49.784 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 757: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "/home/popov/Documents/bots/env/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "2018-11-29 11:24:52.881 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 43: [loading model from /home/popov/.deeppavlov/models/ner_ontonotes/model]\n",
      "2018-11-29 11:24:52.957 INFO in 'tensorflow'['tf_logging'] at line 115: Restoring parameters from /home/popov/.deeppavlov/models/ner_ontonotes/model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[['Computer',\n",
       "   'Sciences',\n",
       "   'Corp.',\n",
       "   'is',\n",
       "   'close',\n",
       "   'to',\n",
       "   'making',\n",
       "   'final',\n",
       "   'an',\n",
       "   'agreement',\n",
       "   'to',\n",
       "   'buy',\n",
       "   'Cleveland',\n",
       "   'Consulting',\n",
       "   'Associates']],\n",
       " [['B-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG']]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model = build_model(configs.ner.ner_ontonotes, download=False)\n",
    "ner_model(['Computer Sciences Corp. is close to making final an agreement to buy Cleveland Consulting Associates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected at least 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-1b8aa79723b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeeppavlov\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_readers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconll2003_reader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConll2003DatasetReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConll2003DatasetReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"../data/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/bots/env/lib/python3.6/site-packages/deeppavlov/dataset_readers/conll2003_reader.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, dir_path, dataset_name, provide_pos)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_ner_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/bots/env/lib/python3.6/site-packages/deeppavlov/dataset_readers/conll2003_reader.py\u001b[0m in \u001b[0;36mparse_ner_file\u001b[0;34m(self, file_name)\u001b[0m\n\u001b[1;32m     61\u001b[0m                         \u001b[0mpos_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                         \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                     \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                     \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected at least 2, got 0)"
     ]
    }
   ],
   "source": [
    "from deeppavlov.dataset_readers.conll2003_reader import Conll2003DatasetReader\n",
    "\n",
    "data = Conll2003DatasetReader().read(dir_path=\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Conll2003DatasetReader(DatasetReader):\n",
      "    \"\"\"Class to read training datasets in CoNLL-2003 format\"\"\"\n",
      "\n",
      "    def read(self, dir_path: str, dataset_name=None, provide_pos=False):\n",
      "        self.provide_pos = provide_pos\n",
      "        dir_path = Path(dir_path)\n",
      "        files = list(dir_path.glob('*.txt'))\n",
      "        if 'train.txt' not in {file_path.name for file_path in files}:\n",
      "            if dataset_name == 'conll2003':\n",
      "                url = 'http://files.deeppavlov.ai/deeppavlov_data/conll2003_v2.tar.gz'\n",
      "            elif dataset_name == 'collection_rus':\n",
      "                url = 'http://files.deeppavlov.ai/deeppavlov_data/collection5.tar.gz'\n",
      "            else:\n",
      "                raise RuntimeError('train.txt not found in \"{}\"'.format(dir_path))\n",
      "            dir_path.mkdir(exist_ok=True, parents=True)\n",
      "            download_decompress(url, dir_path)\n",
      "            files = list(dir_path.glob('*.txt'))\n",
      "        dataset = {}\n",
      "        for file_name in files:\n",
      "            name = file_name.with_suffix('').name\n",
      "            dataset[name] = self.parse_ner_file(file_name)\n",
      "        return dataset\n",
      "\n",
      "    def parse_ner_file(self, file_name: Path):\n",
      "        samples = []\n",
      "        with file_name.open(encoding='utf8') as f:\n",
      "            tokens = ['<DOCSTART>']\n",
      "            pos_tags = ['O']\n",
      "            tags = ['O']\n",
      "            for line in f:\n",
      "                # Check end of the document\n",
      "                if 'DOCSTART' in line:\n",
      "                    if len(tokens) > 1:\n",
      "                        if self.provide_pos:\n",
      "                            samples.append(((tokens, pos_tags), tags, ))\n",
      "                        else:\n",
      "                            samples.append((tokens, tags,))\n",
      "                        tokens = []\n",
      "                        pos_tags = []\n",
      "                        tags = []\n",
      "                elif len(line) < 2:\n",
      "                    if len(tokens) > 0:\n",
      "                        if self.provide_pos:\n",
      "                            samples.append(((tokens, pos_tags), tags, ))\n",
      "                        else:\n",
      "                            samples.append((tokens, tags,))\n",
      "                        tokens = []\n",
      "                        pos_tags = []\n",
      "                        tags = []\n",
      "                else:\n",
      "                    if self.provide_pos:\n",
      "                        token, pos, *_, tag = line.split()\n",
      "                        pos_tags.append(pos)\n",
      "                    else:\n",
      "                        token, *_, tag = line.split()\n",
      "                    tags.append(tag)\n",
      "                    tokens.append(token)\n",
      "\n",
      "        return samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "print(inspect.getsource(Conll2003DatasetReader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 11:45:13.927 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 100: [loading vocabulary from /home/popov/.deeppavlov/models/ner_ontonotes/tag.dict]\n",
      "2018-11-29 11:45:13.963 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 100: [loading vocabulary from /home/popov/.deeppavlov/models/ner_ontonotes/char.dict]\n",
      "2018-11-29 11:45:13.969 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/home/popov/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
      "2018-11-29 11:45:13.970 INFO in 'gensim.models.keyedvectors'['keyedvectors'] at line 204: loading projection weights from /home/popov/.deeppavlov/downloads/embeddings/glove.6B.100d.txt\n",
      "2018-11-29 11:45:13.972 DEBUG in 'smart_open.smart_open_lib'['smart_open_lib'] at line 176: {'kw': {}, 'mode': 'rb', 'uri': '/home/popov/.deeppavlov/downloads/embeddings/glove.6B.100d.txt'}\n",
      "2018-11-29 11:46:07.445 INFO in 'gensim.models.keyedvectors'['keyedvectors'] at line 266: loaded (400000, 100) matrix from /home/popov/.deeppavlov/downloads/embeddings/glove.6B.100d.txt\n",
      "2018-11-29 11:46:10.483 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 757: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2018-11-29 11:46:10.661 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 757: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2018-11-29 11:46:15.176 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 43: [loading model from /home/popov/.deeppavlov/models/ner_ontonotes/model]\n",
      "2018-11-29 11:46:15.272 INFO in 'tensorflow'['tf_logging'] at line 115: Restoring parameters from /home/popov/.deeppavlov/models/ner_ontonotes/model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[['Computer',\n",
       "   'Sciences',\n",
       "   'Corp.',\n",
       "   'is',\n",
       "   'close',\n",
       "   'to',\n",
       "   'making',\n",
       "   'final',\n",
       "   'an',\n",
       "   'agreement',\n",
       "   'to',\n",
       "   'buy',\n",
       "   'Cleveland',\n",
       "   'Consulting',\n",
       "   'Associates']],\n",
       " [['B-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-ORG',\n",
       "   'I-ORG',\n",
       "   'I-ORG']]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model = build_model(\"ner_config.json\", download=False)\n",
    "ner_model(['Computer Sciences Corp. is close to making final an agreement to buy Cleveland Consulting Associates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 12:06:00.128 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 89: [saving vocabulary to /home/popov/.deeppavlov/models/ner/tag.dict]\n",
      "2018-11-29 12:06:01.26 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 89: [saving vocabulary to /home/popov/.deeppavlov/models/ner/char.dict]\n",
      "2018-11-29 12:06:01.28 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/home/popov/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
      "2018-11-29 12:06:01.30 INFO in 'gensim.models.keyedvectors'['keyedvectors'] at line 204: loading projection weights from /home/popov/.deeppavlov/downloads/embeddings/glove.6B.100d.txt\n",
      "2018-11-29 12:06:01.32 DEBUG in 'smart_open.smart_open_lib'['smart_open_lib'] at line 176: {'kw': {}, 'mode': 'rb', 'uri': '/home/popov/.deeppavlov/downloads/embeddings/glove.6B.100d.txt'}\n",
      "2018-11-29 12:07:01.46 INFO in 'gensim.models.keyedvectors'['keyedvectors'] at line 266: loaded (400000, 100) matrix from /home/popov/.deeppavlov/downloads/embeddings/glove.6B.100d.txt\n",
      "2018-11-29 12:07:04.885 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 757: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2018-11-29 12:07:05.102 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 757: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "/home/popov/Documents/bots/env/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "2018-11-29 12:07:15.287 INFO in 'deeppavlov.core.commands.train'['train'] at line 363: New best ner_f1 of 0.2976\n",
      "2018-11-29 12:07:15.289 INFO in 'deeppavlov.core.commands.train'['train'] at line 365: Saving model\n",
      "2018-11-29 12:07:15.291 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /home/popov/.deeppavlov/models/ner/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 1128, \"metrics\": {\"ner_f1\": 0.2976}, \"time_spent\": \"0:00:07\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 12:09:11.406 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 88.3769\n",
      "2018-11-29 12:09:13.80 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
      "2018-11-29 12:09:13.84 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /home/popov/.deeppavlov/models/ner/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 1128, \"metrics\": {\"ner_f1\": 88.3769}, \"time_spent\": \"0:02:03\", \"epochs_done\": 1, \"batches_seen\": 153, \"train_examples_seen\": 9775, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 12:11:20.697 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 92.1925\n",
      "2018-11-29 12:11:20.698 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
      "2018-11-29 12:11:20.701 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /home/popov/.deeppavlov/models/ner/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 1128, \"metrics\": {\"ner_f1\": 92.1925}, \"time_spent\": \"0:04:13\", \"epochs_done\": 2, \"batches_seen\": 306, \"train_examples_seen\": 19550, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 12:13:11.84 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 92.908\n",
      "2018-11-29 12:13:11.86 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
      "2018-11-29 12:13:11.87 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /home/popov/.deeppavlov/models/ner/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 1128, \"metrics\": {\"ner_f1\": 92.908}, \"time_spent\": \"0:06:03\", \"epochs_done\": 3, \"batches_seen\": 459, \"train_examples_seen\": 29325, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 12:14:59.623 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 93.4312\n",
      "2018-11-29 12:14:59.625 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
      "2018-11-29 12:14:59.626 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /home/popov/.deeppavlov/models/ner/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 1128, \"metrics\": {\"ner_f1\": 93.4312}, \"time_spent\": \"0:07:51\", \"epochs_done\": 4, \"batches_seen\": 612, \"train_examples_seen\": 39100, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 12:16:49.996 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 94.0996\n",
      "2018-11-29 12:16:49.997 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
      "2018-11-29 12:16:49.999 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /home/popov/.deeppavlov/models/ner/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 1128, \"metrics\": {\"ner_f1\": 94.0996}, \"time_spent\": \"0:09:42\", \"epochs_done\": 5, \"batches_seen\": 765, \"train_examples_seen\": 48875, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 12:18:45.663 INFO in 'deeppavlov.core.commands.train'['train'] at line 595: Stopped training\n",
      "2018-11-29 12:18:46.475 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 100: [loading vocabulary from /home/popov/.deeppavlov/models/ner/tag.dict]\n",
      "2018-11-29 12:18:46.707 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 100: [loading vocabulary from /home/popov/.deeppavlov/models/ner/char.dict]\n",
      "2018-11-29 12:18:46.787 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/home/popov/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
      "2018-11-29 12:18:46.788 INFO in 'gensim.models.keyedvectors'['keyedvectors'] at line 204: loading projection weights from /home/popov/.deeppavlov/downloads/embeddings/glove.6B.100d.txt\n",
      "2018-11-29 12:18:46.817 DEBUG in 'smart_open.smart_open_lib'['smart_open_lib'] at line 176: {'kw': {}, 'mode': 'rb', 'uri': '/home/popov/.deeppavlov/downloads/embeddings/glove.6B.100d.txt'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-d22e618d9592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeeppavlov\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mner_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ner_config.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/bots/env/lib/python3.6/site-packages/deeppavlov/__init__.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(config, download)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# TODO: make better and add typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mtrain_evaluate_model_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_trained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/bots/env/lib/python3.6/site-packages/deeppavlov/core/commands/train.py\u001b[0m in \u001b[0;36mtrain_evaluate_model_from_config\u001b[0;34m(config, iterator, to_train, to_validate, download, start_epoch_num, recursive)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validate_best'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_best'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_trained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing the best saved model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/bots/env/lib/python3.6/site-packages/deeppavlov/core/commands/infer.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(config, mode, load_trained, download)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 log.warning('No \"save_path\" parameter for the {} component, so \"load_path\" will not be renewed'\n\u001b[1;32m     49\u001b[0m                             .format(component_config.get('class_name', component_config.get('ref', 'UNKNOWN'))))\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mcomponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'in'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomponent_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/bots/env/lib/python3.6/site-packages/deeppavlov/core/common/params.py\u001b[0m in \u001b[0;36mfrom_params\u001b[0;34m(params, mode, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mode'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mcomponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0m_refs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/bots/env/lib/python3.6/site-packages/deeppavlov/models/embedders/abstract_embedder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load_path, pad_zero, mean, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdestroy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/bots/env/lib/python3.6/site-packages/deeppavlov/models/embedders/glove_embedder.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \"\"\"\n\u001b[1;32m     52\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[loading GloVe embeddings from `{self.load_path}`]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/bots/env/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    254\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid vector on line %s (is this really the text format?)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mline_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                     \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m                     \u001b[0madd_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from deeppavlov import train_model\n",
    "ner_model = train_model(\"ner_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 12:20:18.561 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 100: [loading vocabulary from /home/popov/.deeppavlov/models/ner/tag.dict]\n",
      "2018-11-29 12:20:18.594 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 100: [loading vocabulary from /home/popov/.deeppavlov/models/ner/char.dict]\n",
      "2018-11-29 12:20:18.614 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/home/popov/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
      "2018-11-29 12:20:18.615 INFO in 'gensim.models.keyedvectors'['keyedvectors'] at line 204: loading projection weights from /home/popov/.deeppavlov/downloads/embeddings/glove.6B.100d.txt\n",
      "2018-11-29 12:20:18.616 DEBUG in 'smart_open.smart_open_lib'['smart_open_lib'] at line 176: {'kw': {}, 'mode': 'rb', 'uri': '/home/popov/.deeppavlov/downloads/embeddings/glove.6B.100d.txt'}\n",
      "2018-11-29 12:21:15.133 INFO in 'gensim.models.keyedvectors'['keyedvectors'] at line 266: loaded (400000, 100) matrix from /home/popov/.deeppavlov/downloads/embeddings/glove.6B.100d.txt\n",
      "2018-11-29 12:21:18.61 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 757: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2018-11-29 12:21:18.291 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 757: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2018-11-29 12:21:21.358 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 43: [loading model from /home/popov/.deeppavlov/models/ner/model]\n",
      "2018-11-29 12:21:21.425 INFO in 'tensorflow'['tf_logging'] at line 115: Restoring parameters from /home/popov/.deeppavlov/models/ner/model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[['I',\n",
       "   'want',\n",
       "   'to',\n",
       "   'watch',\n",
       "   'an',\n",
       "   'action',\n",
       "   'film',\n",
       "   'with',\n",
       "   'Arnold',\n",
       "   'Swarzenneger']],\n",
       " [['O', 'O', 'O', 'O', 'O', 'B-GENRE', 'O', 'O', 'B-ACTOR', 'I-ACTOR']]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model = build_model(\"ner_config.json\", download=False)\n",
    "ner_model(['I want to watch an action film with Arnold Swarzenneger'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['I',\n",
       "   'want',\n",
       "   'to',\n",
       "   'watch',\n",
       "   'an',\n",
       "   'action',\n",
       "   'film',\n",
       "   'directed',\n",
       "   'by',\n",
       "   'Arnold',\n",
       "   'Swarzenneger']],\n",
       " [['O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-GENRE',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-DIRECTOR',\n",
       "   'I-DIRECTOR']]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model(['I want to watch an action film directed by Arnold Swarzenneger'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
